"""
Experiment Runner v0.6

æ‰¹é‡å¯¦é©—åŸ·è¡Œå¼•æ“ - ä¸¦è¡ŒåŸ·è¡Œã€è¨˜æ†¶é«”ç®¡ç†ã€å¤±æ•—å®¹éŒ¯

æ ¸å¿ƒåŠŸèƒ½:
- ä¸¦è¡Œä»»å‹™åŸ·è¡Œï¼ˆThreadPoolExecutorï¼‰
- å…§å­˜ç®¡ç†å’Œçµæœæµå¼å¯«å…¥
- å¤±æ•—å®¹éŒ¯å’Œé‡è©¦æ©Ÿåˆ¶
- é€²åº¦è¿½è¹¤å’Œç‹€æ…‹æ›´æ–°
- çµæœæ”¶é›†å’Œå­˜å„²

Version: v0.6 Phase 2
Design Reference: docs/specs/v0.6/superdog_v06_strategy_lab_spec.md
"""

from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional, Callable
from datetime import datetime
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import itertools
import json
import hashlib
import time
from tqdm import tqdm

from .experiments import (
    ExperimentConfig,
    ExperimentRun,
    ExperimentResult,
    ExperimentStatus,
    ParameterRange
)


class ParameterExpander:
    """åƒæ•¸çµ„åˆå±•é–‹å™¨

    è² è²¬å°‡åƒæ•¸ç¯„åœå±•é–‹ç‚ºå…·é«”çš„åƒæ•¸çµ„åˆ
    æ”¯æ´ç¶²æ ¼æœç´¢å’Œéš¨æ©Ÿæ¡æ¨£
    """

    def __init__(self, config: ExperimentConfig):
        """åˆå§‹åŒ–

        Args:
            config: å¯¦é©—é…ç½®
        """
        self.config = config

    def expand_combinations(self) -> List[Dict[str, Any]]:
        """å±•é–‹æ‰€æœ‰åƒæ•¸çµ„åˆ

        Returns:
            List[Dict]: åƒæ•¸çµ„åˆåˆ—è¡¨

        Example:
            >>> expander = ParameterExpander(config)
            >>> combinations = expander.expand_combinations()
            >>> len(combinations)
            100
        """
        # å±•é–‹æ¯å€‹åƒæ•¸çš„å€¼åˆ—è¡¨
        param_values = {}
        for name, param_range in self.config.parameters.items():
            param_values[name] = param_range.expand()

        # ç”Ÿæˆæ‰€æœ‰çµ„åˆ
        param_names = list(param_values.keys())
        value_lists = [param_values[name] for name in param_names]

        combinations = []
        for values in itertools.product(*value_lists):
            combo = dict(zip(param_names, values))
            combinations.append(combo)

        # æ‡‰ç”¨æ¡æ¨£ç­–ç•¥
        if self.config.expansion_mode.value == "random":
            combinations = self._random_sample(combinations)
        elif self.config.max_combinations and len(combinations) > self.config.max_combinations:
            # ç¶²æ ¼æ¨¡å¼ä½†è¶…éé™åˆ¶ï¼Œé€²è¡Œæ¡æ¨£
            combinations = self._grid_sample(combinations)

        return combinations

    def _random_sample(self, combinations: List[Dict]) -> List[Dict]:
        """éš¨æ©Ÿæ¡æ¨£

        Args:
            combinations: æ‰€æœ‰çµ„åˆ

        Returns:
            List[Dict]: æ¡æ¨£å¾Œçš„çµ„åˆ
        """
        import random

        sample_size = self.config.sample_size or self.config.max_combinations
        if sample_size and len(combinations) > sample_size:
            return random.sample(combinations, sample_size)
        return combinations

    def _grid_sample(self, combinations: List[Dict]) -> List[Dict]:
        """ç¶²æ ¼æ¡æ¨£ï¼ˆå‡å‹»æ¡æ¨£ï¼‰

        Args:
            combinations: æ‰€æœ‰çµ„åˆ

        Returns:
            List[Dict]: æ¡æ¨£å¾Œçš„çµ„åˆ
        """
        max_count = self.config.max_combinations
        if not max_count or len(combinations) <= max_count:
            return combinations

        # å‡å‹»æ¡æ¨£
        step = len(combinations) // max_count
        return combinations[::step][:max_count]

    def expand_tasks(self) -> List[Dict[str, Any]]:
        """å±•é–‹æ‰€æœ‰å¯¦é©—ä»»å‹™ï¼ˆsymbol Ã— parameter combinationsï¼‰

        Returns:
            List[Dict]: ä»»å‹™åˆ—è¡¨ï¼Œæ¯å€‹ä»»å‹™åŒ…å« symbol å’Œ parameters
        """
        combinations = self.expand_combinations()

        tasks = []
        for symbol in self.config.symbols:
            for params in combinations:
                tasks.append({
                    'symbol': symbol,
                    'parameters': params
                })

        return tasks


class ExperimentRunner:
    """å¯¦é©—æ‰¹é‡åŸ·è¡Œå¼•æ“

    æ ¸å¿ƒåŠŸèƒ½:
    1. ä¸¦è¡ŒåŸ·è¡Œå¯¦é©—ä»»å‹™
    2. å…§å­˜ç®¡ç†ï¼ˆæµå¼å¯«å…¥çµæœï¼‰
    3. å¤±æ•—å®¹éŒ¯å’Œé‡è©¦
    4. é€²åº¦è¿½è¹¤
    """

    def __init__(
        self,
        max_workers: int = 4,
        retry_failed: bool = True,
        max_retries: int = 2,
        fail_fast: bool = False,
        progress_callback: Optional[Callable] = None
    ):
        """åˆå§‹åŒ–

        Args:
            max_workers: æœ€å¤§ä¸¦è¡Œä»»å‹™æ•¸
            retry_failed: æ˜¯å¦é‡è©¦å¤±æ•—ä»»å‹™
            max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸
            fail_fast: é‡åˆ°éŒ¯èª¤ç«‹å³åœæ­¢
            progress_callback: é€²åº¦å›èª¿å‡½æ•¸
        """
        self.max_workers = max_workers
        self.retry_failed = retry_failed
        self.max_retries = max_retries
        self.fail_fast = fail_fast
        self.progress_callback = progress_callback

    def run_experiment(
        self,
        config: ExperimentConfig,
        backtest_func: Callable[[str, str, Dict, ExperimentConfig], Dict]
    ) -> ExperimentResult:
        """åŸ·è¡Œå®Œæ•´å¯¦é©—

        Args:
            config: å¯¦é©—é…ç½®
            backtest_func: å›æ¸¬å‡½æ•¸ï¼Œç°½åç‚º (symbol, timeframe, params, config) -> metrics_dict

        Returns:
            ExperimentResult: å¯¦é©—çµæœ

        Example:
            >>> def my_backtest(symbol, timeframe, params, config):
            ...     # é‹è¡Œå›æ¸¬
            ...     return {'total_return': 0.15, 'sharpe_ratio': 1.5, ...}
            >>>
            >>> runner = ExperimentRunner(max_workers=4)
            >>> result = runner.run_experiment(config, my_backtest)
        """
        experiment_id = config.get_experiment_id()

        print(f"ğŸš€ é–‹å§‹å¯¦é©—: {config.name}")
        print(f"ğŸ“‹ å¯¦é©—ID: {experiment_id}")

        # å±•é–‹ä»»å‹™
        expander = ParameterExpander(config)
        tasks = expander.expand_tasks()

        total_tasks = len(tasks)
        print(f"ğŸ“Š ç¸½ä»»å‹™æ•¸: {total_tasks}")
        print(f"ğŸ’° å¹£ç¨®æ•¸: {len(config.symbols)}")
        print(f"âš™ï¸  åƒæ•¸çµ„åˆæ•¸: {len(expander.expand_combinations())}")
        print(f"ğŸ‘· ä¸¦è¡Œå·¥ä½œæ•¸: {self.max_workers}")

        # åˆå§‹åŒ–çµæœ
        runs: List[ExperimentRun] = []
        started_at = datetime.now().isoformat()

        # ä¸¦è¡ŒåŸ·è¡Œ
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»å‹™
            future_to_task = {}
            for i, task in enumerate(tasks):
                run_id = f"{experiment_id}_run_{i:06d}"
                future = executor.submit(
                    self._execute_single_run,
                    run_id=run_id,
                    experiment_id=experiment_id,
                    symbol=task['symbol'],
                    parameters=task['parameters'],
                    config=config,
                    backtest_func=backtest_func
                )
                future_to_task[future] = task

            # æ”¶é›†çµæœï¼ˆå¸¶é€²åº¦æ¢ï¼‰
            completed = 0
            failed_count = 0

            with tqdm(total=total_tasks, desc="åŸ·è¡Œé€²åº¦") as pbar:
                for future in as_completed(future_to_task):
                    try:
                        run = future.result()
                        runs.append(run)

                        if run.status == ExperimentStatus.FAILED:
                            failed_count += 1
                            if self.fail_fast:
                                print(f"\nâŒ ä»»å‹™å¤±æ•—ï¼ˆfail_fast æ¨¡å¼ï¼‰ï¼Œåœæ­¢åŸ·è¡Œ")
                                executor.shutdown(wait=False, cancel_futures=True)
                                break

                        # æµå¼å¯«å…¥çµæœï¼ˆç¯€çœå…§å­˜ï¼‰
                        if completed % 10 == 0:
                            self._flush_results(experiment_id, runs[-10:])

                    except Exception as e:
                        failed_count += 1
                        print(f"\nâš ï¸  ä»»å‹™åŸ·è¡Œç•°å¸¸: {e}")
                        if self.fail_fast:
                            executor.shutdown(wait=False, cancel_futures=True)
                            break

                    completed += 1
                    pbar.update(1)

                    if self.progress_callback:
                        self.progress_callback(completed, total_tasks, failed_count)

        completed_at = datetime.now().isoformat()
        duration = (datetime.fromisoformat(completed_at) - datetime.fromisoformat(started_at)).total_seconds()

        # çµ±è¨ˆçµæœ
        completed_runs = len([r for r in runs if r.status == ExperimentStatus.COMPLETED])
        failed_runs = len([r for r in runs if r.status == ExperimentStatus.FAILED])

        print(f"\nâœ… å¯¦é©—å®Œæˆï¼")
        print(f"â±ï¸  åŸ·è¡Œæ™‚é–“: {duration:.1f} ç§’")
        print(f"âœ… æˆåŠŸ: {completed_runs}/{total_tasks}")
        print(f"âŒ å¤±æ•—: {failed_runs}/{total_tasks}")

        # å‰µå»ºçµæœå°è±¡
        result = ExperimentResult(
            experiment_id=experiment_id,
            config=config,
            runs=runs,
            total_runs=total_tasks,
            completed_runs=completed_runs,
            failed_runs=failed_runs,
            started_at=started_at,
            completed_at=completed_at,
            duration_seconds=duration
        )

        # æ‰¾å‡ºæœ€ä½³åŸ·è¡Œ
        result.best_run = result.get_best_run(metric=config.tags[0] if config.tags else "sharpe_ratio")

        return result

    def _execute_single_run(
        self,
        run_id: str,
        experiment_id: str,
        symbol: str,
        parameters: Dict[str, Any],
        config: ExperimentConfig,
        backtest_func: Callable
    ) -> ExperimentRun:
        """åŸ·è¡Œå–®å€‹å¯¦é©—é‹è¡Œ

        åŒ…å«é‡è©¦é‚è¼¯å’ŒéŒ¯èª¤è™•ç†

        Args:
            run_id: é‹è¡ŒID
            experiment_id: å¯¦é©—ID
            symbol: äº¤æ˜“å°
            parameters: åƒæ•¸çµ„åˆ
            config: å¯¦é©—é…ç½®
            backtest_func: å›æ¸¬å‡½æ•¸

        Returns:
            ExperimentRun: é‹è¡Œè¨˜éŒ„
        """
        run = ExperimentRun(
            experiment_id=experiment_id,
            run_id=run_id,
            symbol=symbol,
            parameters=parameters,
            status=ExperimentStatus.PENDING
        )

        retries = 0
        while retries <= self.max_retries:
            try:
                # æ¨™è¨˜ç‚ºé‹è¡Œä¸­
                run.status = ExperimentStatus.RUNNING
                run.started_at = datetime.now().isoformat()

                # åŸ·è¡Œå›æ¸¬
                metrics = backtest_func(symbol, config.timeframe, parameters, config)

                # è¨˜éŒ„çµæœ
                run.total_return = metrics.get('total_return')
                run.max_drawdown = metrics.get('max_drawdown')
                run.sharpe_ratio = metrics.get('sharpe_ratio')
                run.num_trades = metrics.get('num_trades')
                run.win_rate = metrics.get('win_rate')
                run.profit_factor = metrics.get('profit_factor')

                # ä¿å­˜é¡å¤–æŒ‡æ¨™
                run.metrics = {k: v for k, v in metrics.items()
                              if k not in ['total_return', 'max_drawdown', 'sharpe_ratio',
                                          'num_trades', 'win_rate', 'profit_factor']}

                # æ¨™è¨˜å®Œæˆ
                run.status = ExperimentStatus.COMPLETED
                run.completed_at = datetime.now().isoformat()

                return run

            except Exception as e:
                retries += 1
                error_msg = f"{type(e).__name__}: {str(e)}"

                if retries > self.max_retries or not self.retry_failed:
                    # æ¨™è¨˜å¤±æ•—
                    run.status = ExperimentStatus.FAILED
                    run.error_message = error_msg
                    run.completed_at = datetime.now().isoformat()
                    return run
                else:
                    # ç­‰å¾…å¾Œé‡è©¦
                    time.sleep(0.5 * retries)

        return run

    def _flush_results(self, experiment_id: str, runs: List[ExperimentRun]):
        """æµå¼å¯«å…¥çµæœåˆ°ç£ç›¤ï¼ˆç¯€çœå…§å­˜ï¼‰

        Args:
            experiment_id: å¯¦é©—ID
            runs: é‹è¡Œè¨˜éŒ„åˆ—è¡¨
        """
        output_dir = Path("data/experiments/results") / experiment_id
        output_dir.mkdir(parents=True, exist_ok=True)

        # è¿½åŠ æ¨¡å¼å¯«å…¥
        output_file = output_dir / "runs.jsonl"
        with open(output_file, 'a') as f:
            for run in runs:
                f.write(json.dumps(run.to_dict()) + '\n')

    def save_result(self, result: ExperimentResult, output_path: Optional[str] = None):
        """ä¿å­˜å®Œæ•´å¯¦é©—çµæœ

        Args:
            result: å¯¦é©—çµæœ
            output_path: è¼¸å‡ºè·¯å¾‘ï¼ˆé»˜èªç‚º data/experiments/results/{experiment_id}/ï¼‰
        """
        if output_path is None:
            output_dir = Path("data/experiments/results") / result.experiment_id
        else:
            output_dir = Path(output_path)

        output_dir.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜æ‘˜è¦
        summary_file = output_dir / "summary.json"
        with open(summary_file, 'w') as f:
            json.dump(result.to_dict(), f, indent=2, ensure_ascii=False)

        # ä¿å­˜é…ç½®
        config_file = output_dir / "config.json"
        result.config.save(str(config_file))

        # ä¿å­˜æ‰€æœ‰é‹è¡Œè¨˜éŒ„ï¼ˆå¦‚æœé‚„æ²’å¯«å…¥ï¼‰
        runs_file = output_dir / "runs.jsonl"
        if not runs_file.exists():
            with open(runs_file, 'w') as f:
                for run in result.runs:
                    f.write(json.dumps(run.to_dict()) + '\n')

        print(f"ğŸ’¾ çµæœå·²ä¿å­˜: {output_dir}")

    def load_result(self, experiment_id: str) -> ExperimentResult:
        """åŠ è¼‰å¯¦é©—çµæœ

        Args:
            experiment_id: å¯¦é©—ID

        Returns:
            ExperimentResult: å¯¦é©—çµæœ
        """
        result_dir = Path("data/experiments/results") / experiment_id

        # åŠ è¼‰æ‘˜è¦
        summary_file = result_dir / "summary.json"
        with open(summary_file, 'r') as f:
            data = json.load(f)

        # é‡å»ºå°è±¡
        config = ExperimentConfig.from_dict(data['config'])

        runs = []
        for run_data in data['runs']:
            runs.append(ExperimentRun.from_dict(run_data))

        result = ExperimentResult(
            experiment_id=data['experiment_id'],
            config=config,
            runs=runs,
            total_runs=data['total_runs'],
            completed_runs=data['completed_runs'],
            failed_runs=data['failed_runs'],
            started_at=data['started_at'],
            completed_at=data['completed_at'],
            duration_seconds=data['duration_seconds']
        )

        if data['best_run']:
            result.best_run = ExperimentRun.from_dict(data['best_run'])

        return result


# ===== ä¾¿æ·å‡½æ•¸ =====

def run_experiment(
    config: ExperimentConfig,
    backtest_func: Callable,
    max_workers: int = 4,
    **runner_kwargs
) -> ExperimentResult:
    """é‹è¡Œå¯¦é©—çš„ä¾¿æ·å‡½æ•¸

    Args:
        config: å¯¦é©—é…ç½®
        backtest_func: å›æ¸¬å‡½æ•¸
        max_workers: æœ€å¤§ä¸¦è¡Œæ•¸
        **runner_kwargs: å‚³éçµ¦ ExperimentRunner çš„å…¶ä»–åƒæ•¸

    Returns:
        ExperimentResult: å¯¦é©—çµæœ

    Example:
        >>> def my_backtest(symbol, timeframe, params, config):
        ...     # åŸ·è¡Œå›æ¸¬
        ...     return metrics
        >>>
        >>> config = create_experiment_config(...)
        >>> result = run_experiment(config, my_backtest, max_workers=8)
    """
    runner = ExperimentRunner(max_workers=max_workers, **runner_kwargs)
    result = runner.run_experiment(config, backtest_func)
    runner.save_result(result)
    return result
