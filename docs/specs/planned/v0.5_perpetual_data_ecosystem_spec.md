# SuperDog Backtest v0.5 Technical Specification
**æ°¸çºŒåˆç´„æ•¸æ“šç”Ÿæ…‹ç³»çµ± (Perpetual Contract Data Ecosystem)**

**ç‰ˆæœ¬**: v0.5.0
**ç‹€æ…‹**: è¨­è¨ˆéšæ®µ
**å„ªå…ˆç´š**: é«˜ (åŸºæ–¼v0.4æˆåŠŸåŸºç¤)
**é è¨ˆå®Œæˆ**: 3-4é€±

---

## ğŸ¯ è¨­è¨ˆç›®æ¨™

### **æ ¸å¿ƒå•é¡Œ**
- v0.4åƒ…æ”¯æ´OHLCVåŸºç¤æ•¸æ“šï¼Œç„¡æ³•é€²è¡Œæ·±åº¦æ°¸çºŒåˆç´„åˆ†æ
- ç¼ºä¹è³‡é‡‘è²»ç‡ã€æŒå€‰é‡ã€åŸºå·®ç­‰é—œéµæ°¸çºŒåˆç´„æŒ‡æ¨™
- å–®ä¸€æ•¸æ“šæºé™åˆ¶ï¼Œç„¡æ³•ç²å¾—å®Œæ•´å¸‚å ´åœ–æ™¯
- æ‰‹å‹•æ•¸æ“šç®¡ç†ï¼Œç¼ºä¹è‡ªå‹•åŒ–æ•¸æ“šå“è³ªæ§åˆ¶

### **è§£æ±ºæ–¹æ¡ˆ**
- **æ°¸çºŒåˆç´„å°ˆç²¾æ•¸æ“šæº** - 7å¤§é—œéµæ•¸æ“šé¡å‹
- **å¤šäº¤æ˜“æ‰€æ•¸æ“šèšåˆ** - Binance/Bybit/OKXçµ±ä¸€æ¥å…¥
- **å¯¦æ™‚æ•¸æ“šæµæ¶æ§‹** - ç‚ºå¯¦ç›¤äº¤æ˜“åšæº–å‚™
- **æ™ºèƒ½æ•¸æ“šå“è³ªæ§åˆ¶** - è‡ªå‹•æª¢æ¸¬ã€ä¿®å¾©ã€è£œé½Š
- **äº’å‹•å¼CLIå‡ç´š** - é¸å–®å¼æ“ä½œé«”é©—

---

## ğŸ“Š æ•¸æ“šæºæ¶æ§‹è¨­è¨ˆ

### **v0.5 æ–°å¢æ•¸æ“šæº**

```python
class DataSource(Enum):
    # v0.4 ç¾æœ‰
    OHLCV = "ohlcv"

    # v0.5 æ°¸çºŒåˆç´„å°ˆç²¾æ•¸æ“šæº
    FUNDING_RATE = "funding_rate"        # è³‡é‡‘è²»ç‡ (8å°æ™‚)
    OPEN_INTEREST = "open_interest"      # æŒå€‰é‡
    BASIS = "basis"                      # æœŸç¾åŸºå·®
    LIQUIDATIONS = "liquidations"        # çˆ†å€‰æ•¸æ“š
    LONG_SHORT_RATIO = "long_short"      # å¤šç©ºæŒå€‰æ¯”
    TOP_ACCOUNTS = "top_accounts"        # å¤§æˆ¶æŒå€‰æ•¸æ“š
    VOLUME_PROFILE = "volume_profile"    # æˆäº¤é‡åˆ†ä½ˆ
```

### **æ•¸æ“šæºè©³ç´°è¦æ ¼**

#### **1. è³‡é‡‘è²»ç‡ (FUNDING_RATE)**
```python
@dataclass
class FundingRateData:
    """è³‡é‡‘è²»ç‡æ•¸æ“šçµæ§‹"""
    timestamp: pd.Timestamp      # æ™‚é–“æˆ³
    symbol: str                  # äº¤æ˜“å° (BTCUSDT)
    funding_rate: float          # è³‡é‡‘è²»ç‡ (-0.01 to 0.01)
    predicted_rate: float        # é æ¸¬è³‡é‡‘è²»ç‡
    mark_price: float           # æ¨™è¨˜åƒ¹æ ¼
    index_price: float          # æŒ‡æ•¸åƒ¹æ ¼
    funding_time: pd.Timestamp  # è³‡é‡‘è²»ç”¨æ™‚é–“
    exchange: str               # äº¤æ˜“æ‰€ (binance/bybit/okx)

# æ•¸æ“šé »ç‡ï¼š8å°æ™‚ (00:00, 08:00, 16:00 UTC)
# æ­·å²æ·±åº¦ï¼š365å¤©
# æ•¸æ“šä¾†æºï¼šBinance, Bybit, OKX
```

#### **2. æŒå€‰é‡ (OPEN_INTEREST)**
```python
@dataclass
class OpenInterestData:
    """æŒå€‰é‡æ•¸æ“šçµæ§‹"""
    timestamp: pd.Timestamp      # æ™‚é–“æˆ³
    symbol: str                  # äº¤æ˜“å°
    open_interest: float         # æŒå€‰é‡ (USDTè¨ˆåƒ¹)
    open_interest_value: float   # æŒå€‰é‡åƒ¹å€¼
    change_24h: float           # 24å°æ™‚è®ŠåŒ–
    change_percentage: float     # è®ŠåŒ–ç™¾åˆ†æ¯”
    exchange: str               # äº¤æ˜“æ‰€

# æ•¸æ“šé »ç‡ï¼š5åˆ†é˜
# æ­·å²æ·±åº¦ï¼š180å¤©
# è¨ˆç®—æŒ‡æ¨™ï¼šOIå‹•é‡ã€OI/å¸‚å€¼æ¯”ã€OI divergence
```

#### **3. æœŸç¾åŸºå·® (BASIS)**
```python
@dataclass
class BasisData:
    """æœŸç¾åŸºå·®æ•¸æ“šçµæ§‹"""
    timestamp: pd.Timestamp      # æ™‚é–“æˆ³
    symbol: str                  # äº¤æ˜“å°
    perp_price: float           # æ°¸çºŒåˆç´„åƒ¹æ ¼
    spot_price: float           # ç¾è²¨åƒ¹æ ¼
    basis: float                # åŸºå·® (perp - spot)
    basis_percentage: float      # åŸºå·®ç™¾åˆ†æ¯”
    annualized_basis: float     # å¹´åŒ–åŸºå·®
    exchange: str               # äº¤æ˜“æ‰€

# æ•¸æ“šé »ç‡ï¼š1åˆ†é˜
# æ­·å²æ·±åº¦ï¼š90å¤©
# è¨ˆç®—æŒ‡æ¨™ï¼šåŸºå·®æ”¶æ–‚ã€å‡å€¼å›æ­¸ä¿¡è™Ÿ
```

#### **4. çˆ†å€‰æ•¸æ“š (LIQUIDATIONS)**
```python
@dataclass
class LiquidationData:
    """çˆ†å€‰æ•¸æ“šçµæ§‹"""
    timestamp: pd.Timestamp      # çˆ†å€‰æ™‚é–“
    symbol: str                  # äº¤æ˜“å°
    side: str                   # æ–¹å‘ (long/short)
    size: float                 # çˆ†å€‰æ•¸é‡
    price: float                # çˆ†å€‰åƒ¹æ ¼
    value: float                # çˆ†å€‰åƒ¹å€¼ (USDT)
    exchange: str               # äº¤æ˜“æ‰€

# æ•¸æ“šé »ç‡ï¼šå³æ™‚
# æ­·å²æ·±åº¦ï¼š30å¤©
# èšåˆæŒ‡æ¨™ï¼šçˆ†å€‰æ¯”ç‡ã€çˆ†å€‰å¯†åº¦ã€å¸‚å ´ææ…ŒæŒ‡æ•¸
```

#### **5. å¤šç©ºæŒå€‰æ¯” (LONG_SHORT_RATIO)**
```python
@dataclass
class LongShortRatioData:
    """å¤šç©ºæŒå€‰æ¯”æ•¸æ“šçµæ§‹"""
    timestamp: pd.Timestamp      # æ™‚é–“æˆ³
    symbol: str                  # äº¤æ˜“å°
    long_account_ratio: float    # å¤šé ­è³¬æˆ¶æ¯”ä¾‹
    short_account_ratio: float   # ç©ºé ­è³¬æˆ¶æ¯”ä¾‹
    long_position_ratio: float   # å¤šé ­æŒå€‰æ¯”ä¾‹
    short_position_ratio: float  # ç©ºé ­æŒå€‰æ¯”ä¾‹
    exchange: str               # äº¤æ˜“æ‰€

# æ•¸æ“šé »ç‡ï¼š5åˆ†é˜
# æ­·å²æ·±åº¦ï¼š90å¤©
# é€†å‘æŒ‡æ¨™ï¼šæ¥µç«¯æ¯”ä¾‹çš„åè½‰ä¿¡è™Ÿ
```

---

## ğŸ—ï¸ æ¶æ§‹è¨­è¨ˆ

### **1. æ•¸æ“šç²å–å±¤ (Data Acquisition)**

```python
class ExchangeConnector(ABC):
    """äº¤æ˜“æ‰€é€£æ¥å™¨åŸºåº•é¡åˆ¥"""

    @abstractmethod
    def get_funding_rate(self, symbol: str, start_time: datetime, end_time: datetime) -> pd.DataFrame:
        """ç²å–è³‡é‡‘è²»ç‡æ•¸æ“š"""
        pass

    @abstractmethod
    def get_open_interest(self, symbol: str, interval: str, limit: int) -> pd.DataFrame:
        """ç²å–æŒå€‰é‡æ•¸æ“š"""
        pass

    @abstractmethod
    def get_liquidations(self, symbol: str, start_time: datetime, end_time: datetime) -> pd.DataFrame:
        """ç²å–çˆ†å€‰æ•¸æ“š"""
        pass

class BinanceConnector(ExchangeConnector):
    """Binance æ°¸çºŒåˆç´„æ•¸æ“šé€£æ¥å™¨"""

    def __init__(self, api_key: str = None, secret_key: str = None):
        self.base_url = "https://fapi.binance.com"  # æœŸè²¨API
        self.api_key = api_key
        self.secret_key = secret_key
        self.session = requests.Session()

    def get_funding_rate(self, symbol: str, start_time: datetime, end_time: datetime) -> pd.DataFrame:
        """
        ç²å–Binanceè³‡é‡‘è²»ç‡æ­·å²

        API: GET /fapi/v1/fundingRate
        é™åˆ¶: 1000æ¢/è«‹æ±‚, æ¬Šé‡2
        """
        endpoint = "/fapi/v1/fundingRate"
        params = {
            'symbol': symbol,
            'startTime': int(start_time.timestamp() * 1000),
            'endTime': int(end_time.timestamp() * 1000),
            'limit': 1000
        }
        # å¯¦ä½œAPIèª¿ç”¨é‚è¼¯

    def get_open_interest(self, symbol: str, interval: str = '5m', limit: int = 500) -> pd.DataFrame:
        """
        ç²å–BinanceæŒå€‰é‡æ•¸æ“š

        API: GET /fapi/v1/openInterestHist
        é–“éš”: 5m, 15m, 30m, 1h, 2h, 4h, 6h, 12h, 1d
        """
        endpoint = "/fapi/v1/openInterestHist"
        # å¯¦ä½œé‚è¼¯

class BybitConnector(ExchangeConnector):
    """Bybit æ°¸çºŒåˆç´„æ•¸æ“šé€£æ¥å™¨"""

    def __init__(self):
        self.base_url = "https://api.bybit.com"

    # å¯¦ä½œBybitç‰¹å®šçš„APIèª¿ç”¨

class OKXConnector(ExchangeConnector):
    """OKX æ°¸çºŒåˆç´„æ•¸æ“šé€£æ¥å™¨"""

    def __init__(self):
        self.base_url = "https://www.okx.com"

    # å¯¦ä½œOKXç‰¹å®šçš„APIèª¿ç”¨
```

### **2. æ•¸æ“šæ¨™æº–åŒ–å±¤ (Data Normalization)**

```python
class DataNormalizer:
    """å¤šäº¤æ˜“æ‰€æ•¸æ“šæ¨™æº–åŒ–å™¨"""

    def normalize_funding_rate(self, raw_data: pd.DataFrame, exchange: str) -> pd.DataFrame:
        """
        æ¨™æº–åŒ–è³‡é‡‘è²»ç‡æ•¸æ“šæ ¼å¼

        çµ±ä¸€æ¬„ä½ï¼štimestamp, symbol, funding_rate, predicted_rate, mark_price
        æ™‚å€è½‰æ›ï¼šUTCæ¨™æº–æ™‚é–“
        ç¬¦è™Ÿæ¨™æº–åŒ–ï¼šBTCUSDTæ ¼å¼
        """
        normalized = raw_data.copy()

        # äº¤æ˜“æ‰€ç‰¹å®šè½‰æ›é‚è¼¯
        if exchange == 'binance':
            normalized['funding_rate'] = raw_data['fundingRate'].astype(float)
            normalized['timestamp'] = pd.to_datetime(raw_data['fundingTime'], unit='ms')
        elif exchange == 'bybit':
            # Bybitç‰¹å®šè½‰æ›
            pass

        # çµ±ä¸€æ ¼å¼é©—è­‰
        required_columns = ['timestamp', 'symbol', 'funding_rate']
        assert all(col in normalized.columns for col in required_columns)

        return normalized

    def normalize_open_interest(self, raw_data: pd.DataFrame, exchange: str) -> pd.DataFrame:
        """æ¨™æº–åŒ–æŒå€‰é‡æ•¸æ“š"""
        # é¡ä¼¼å¯¦ä½œ
        pass
```

### **3. æ•¸æ“šå­˜å„²å±¤ (Data Storage)**

```python
class PerpetualDataStorage:
    """æ°¸çºŒåˆç´„æ•¸æ“šå­˜å„²ç®¡ç†å™¨"""

    def __init__(self, config: DataConfig):
        self.config = config
        self.base_path = config.data_root / "perpetual"
        self.setup_directories()

    def setup_directories(self):
        """å»ºç«‹æ•¸æ“šç›®éŒ„çµæ§‹"""
        directories = [
            "funding_rate/binance",
            "funding_rate/bybit",
            "funding_rate/okx",
            "open_interest/binance",
            "open_interest/bybit",
            "liquidations/binance",
            "basis/aggregated",
            "long_short_ratio/binance"
        ]

        for dir_path in directories:
            full_path = self.base_path / dir_path
            full_path.mkdir(parents=True, exist_ok=True)

    def save_funding_rate(self, data: pd.DataFrame, symbol: str, exchange: str):
        """
        ä¿å­˜è³‡é‡‘è²»ç‡æ•¸æ“š

        æ–‡ä»¶æ ¼å¼ï¼šparquet (é«˜æ•ˆå£“ç¸®)
        æ–‡ä»¶å‘½åï¼š{symbol}_{exchange}_{start_date}_{end_date}.parquet
        åˆ†å€ç­–ç•¥ï¼šæŒ‰æœˆä»½åˆ†å€ï¼Œé¿å…å–®æ–‡ä»¶éå¤§
        """
        if data.empty:
            return

        # æŒ‰æœˆä»½åˆ†çµ„ä¿å­˜
        for month, month_data in data.groupby(data['timestamp'].dt.to_period('M')):
            file_path = (self.base_path / "funding_rate" / exchange /
                        f"{symbol}_{month}.parquet")

            # è¿½åŠ æ¨¡å¼ï¼Œé¿å…è¦†è“‹
            if file_path.exists():
                existing_data = pd.read_parquet(file_path)
                combined_data = pd.concat([existing_data, month_data]).drop_duplicates(
                    subset=['timestamp', 'symbol'], keep='last'
                )
                combined_data = combined_data.sort_values('timestamp')
            else:
                combined_data = month_data.sort_values('timestamp')

            combined_data.to_parquet(file_path, index=False)

    def load_funding_rate(self, symbol: str, exchange: str,
                         start_date: datetime, end_date: datetime) -> pd.DataFrame:
        """è¼‰å…¥è³‡é‡‘è²»ç‡æ•¸æ“š"""
        data_frames = []

        # è¨ˆç®—éœ€è¦çš„æœˆä»½ç¯„åœ
        start_month = start_date.replace(day=1)
        end_month = end_date.replace(day=1)

        current_month = start_month
        while current_month <= end_month:
            month_str = current_month.strftime('%Y-%m')
            file_path = (self.base_path / "funding_rate" / exchange /
                        f"{symbol}_{month_str}.parquet")

            if file_path.exists():
                month_data = pd.read_parquet(file_path)
                data_frames.append(month_data)

            # ä¸‹ä¸€å€‹æœˆ
            if current_month.month == 12:
                current_month = current_month.replace(year=current_month.year + 1, month=1)
            else:
                current_month = current_month.replace(month=current_month.month + 1)

        if not data_frames:
            return pd.DataFrame()

        combined_data = pd.concat(data_frames, ignore_index=True)

        # æŒ‰æ™‚é–“ç¯„åœç¯©é¸
        mask = (combined_data['timestamp'] >= start_date) & (combined_data['timestamp'] <= end_date)
        return combined_data[mask].sort_values('timestamp')
```

### **4. æ•¸æ“šå“è³ªæ§åˆ¶å±¤ (Data Quality Control)**

```python
class DataQualityController:
    """æ•¸æ“šå“è³ªæ§åˆ¶å™¨"""

    def __init__(self):
        self.quality_rules = self._load_quality_rules()

    def _load_quality_rules(self) -> Dict[str, Dict]:
        """è¼‰å…¥æ•¸æ“šå“è³ªè¦å‰‡"""
        return {
            'funding_rate': {
                'range': (-0.1, 0.1),           # è³‡é‡‘è²»ç‡åˆç†ç¯„åœ
                'required_columns': ['timestamp', 'symbol', 'funding_rate'],
                'null_tolerance': 0.0,           # ä¸å…è¨±ç©ºå€¼
                'duplicate_check': True          # æª¢æŸ¥é‡è¤‡æ•¸æ“š
            },
            'open_interest': {
                'range': (0, float('inf')),     # æŒå€‰é‡éè² 
                'required_columns': ['timestamp', 'symbol', 'open_interest'],
                'null_tolerance': 0.05,          # å…è¨±5%ç©ºå€¼
                'monotonicity': False            # ä¸è¦æ±‚å–®èª¿æ€§
            },
            'basis': {
                'range': (-0.05, 0.05),         # åŸºå·®åˆç†ç¯„åœ
                'outlier_threshold': 3,          # 3å€‹æ¨™æº–å·®
                'correlation_check': True        # èˆ‡ç¾è²¨åƒ¹æ ¼ç›¸é—œæ€§æª¢æŸ¥
            }
        }

    def validate_data(self, data: pd.DataFrame, data_type: str) -> Tuple[bool, List[str]]:
        """
        é©—è­‰æ•¸æ“šå“è³ª

        Returns:
            (is_valid, error_messages)
        """
        errors = []

        if data_type not in self.quality_rules:
            return False, [f"Unknown data type: {data_type}"]

        rules = self.quality_rules[data_type]

        # 1. æª¢æŸ¥å¿…è¦æ¬„ä½
        required_cols = rules.get('required_columns', [])
        missing_cols = [col for col in required_cols if col not in data.columns]
        if missing_cols:
            errors.append(f"Missing columns: {missing_cols}")

        # 2. æª¢æŸ¥æ•¸æ“šç¯„åœ
        if 'range' in rules and len(data) > 0:
            min_val, max_val = rules['range']
            value_col = required_cols[-1] if required_cols else data.columns[-1]

            if value_col in data.columns:
                out_of_range = ((data[value_col] < min_val) | (data[value_col] > max_val)).sum()
                if out_of_range > 0:
                    errors.append(f"{out_of_range} values out of range [{min_val}, {max_val}]")

        # 3. æª¢æŸ¥ç©ºå€¼æ¯”ä¾‹
        null_tolerance = rules.get('null_tolerance', 0.0)
        for col in required_cols:
            if col in data.columns:
                null_ratio = data[col].isnull().sum() / len(data)
                if null_ratio > null_tolerance:
                    errors.append(f"Column {col} has {null_ratio:.2%} null values (max: {null_tolerance:.2%})")

        # 4. æª¢æŸ¥é‡è¤‡æ•¸æ“š
        if rules.get('duplicate_check', False):
            duplicates = data.duplicated(subset=required_cols[:2]).sum()  # timestamp + symbol
            if duplicates > 0:
                errors.append(f"Found {duplicates} duplicate records")

        # 5. é›¢ç¾¤å€¼æª¢æ¸¬
        if 'outlier_threshold' in rules and len(data) > 10:
            value_col = required_cols[-1]
            if value_col in data.columns:
                z_scores = np.abs(stats.zscore(data[value_col].dropna()))
                outliers = (z_scores > rules['outlier_threshold']).sum()
                if outliers > 0:
                    errors.append(f"Found {outliers} outliers (>{rules['outlier_threshold']} std)")

        return len(errors) == 0, errors

    def clean_data(self, data: pd.DataFrame, data_type: str) -> pd.DataFrame:
        """
        æ¸…ç†æ•¸æ“š

        - ç§»é™¤é‡è¤‡è¨˜éŒ„
        - å¡«è£œç¼ºå¤±å€¼
        - ä¿®æ­£é›¢ç¾¤å€¼
        - æ’åºæ™‚é–“åºåˆ—
        """
        if data.empty:
            return data

        cleaned_data = data.copy()
        rules = self.quality_rules.get(data_type, {})

        # 1. ç§»é™¤é‡è¤‡è¨˜éŒ„
        if rules.get('duplicate_check', False):
            required_cols = rules.get('required_columns', [])
            if len(required_cols) >= 2:
                cleaned_data = cleaned_data.drop_duplicates(
                    subset=required_cols[:2], keep='last'
                )

        # 2. æ™‚é–“æ’åº
        if 'timestamp' in cleaned_data.columns:
            cleaned_data = cleaned_data.sort_values('timestamp')

        # 3. è™•ç†ç¼ºå¤±å€¼
        null_tolerance = rules.get('null_tolerance', 0.0)
        if null_tolerance > 0:
            # å‘å‰å¡«è£œ (forward fill)
            cleaned_data = cleaned_data.fillna(method='ffill')

        # 4. é›¢ç¾¤å€¼ä¿®æ­£ (ç”¨ä¸­ä½æ•¸æ›¿æ›)
        if 'outlier_threshold' in rules:
            value_col = rules.get('required_columns', [])[-1]
            if value_col in cleaned_data.columns:
                z_scores = np.abs(stats.zscore(cleaned_data[value_col].fillna(0)))
                outlier_mask = z_scores > rules['outlier_threshold']
                if outlier_mask.any():
                    median_value = cleaned_data[value_col].median()
                    cleaned_data.loc[outlier_mask, value_col] = median_value

        return cleaned_data
```

---

## ğŸ”„ æ•¸æ“šç®¡é“æ•´åˆ

### **æ“´å±•ç¾æœ‰ DataPipeline (v0.4)**

```python
class DataPipeline:  # æ“´å±•ç¾æœ‰é¡åˆ¥
    """çµ±ä¸€æ•¸æ“šç®¡é“ v0.5 - æ°¸çºŒåˆç´„æ•¸æ“šæ”¯æ´"""

    def __init__(self, config: DataConfig):
        self.config = config
        self.storage = PerpetualDataStorage(config)  # æ–°å¢
        self.quality_controller = DataQualityController()  # æ–°å¢
        self.connectors = {
            'binance': BinanceConnector(),
            'bybit': BybitConnector(),
            'okx': OKXConnector()
        }
        self._cache = {}

    def load_strategy_data(
        self,
        strategy: BaseStrategy,
        symbol: str,
        timeframe: str,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        exchanges: List[str] = ['binance']  # v0.5 æ–°å¢
    ) -> Dict[str, pd.DataFrame]:
        """
        æ ¹æ“šç­–ç•¥éœ€æ±‚è¼‰å…¥æ•¸æ“š (v0.5 æ“´å±•)

        æ–°å¢æ”¯æ´ï¼š
        - æ°¸çºŒåˆç´„æ•¸æ“šæº
        - å¤šäº¤æ˜“æ‰€æ•¸æ“šèšåˆ
        - æ•¸æ“šå“è³ªæ§åˆ¶
        """
        requirements = strategy.get_data_requirements()
        loaded_data = {}

        for req in requirements:
            try:
                if req.source == DataSource.OHLCV:
                    # v0.4 ç¾æœ‰é‚è¼¯
                    data = self._load_ohlcv(symbol, timeframe, start_date, end_date)
                    loaded_data[req.source.value] = data

                elif req.source == DataSource.FUNDING_RATE:
                    # v0.5 æ–°å¢ï¼šè³‡é‡‘è²»ç‡æ•¸æ“š
                    funding_data = self._load_funding_rate_multi_exchange(
                        symbol, start_date, end_date, exchanges
                    )
                    loaded_data[req.source.value] = funding_data

                elif req.source == DataSource.OPEN_INTEREST:
                    # v0.5 æ–°å¢ï¼šæŒå€‰é‡æ•¸æ“š
                    oi_data = self._load_open_interest_multi_exchange(
                        symbol, start_date, end_date, exchanges
                    )
                    loaded_data[req.source.value] = oi_data

                elif req.source == DataSource.BASIS:
                    # v0.5 æ–°å¢ï¼šæœŸç¾åŸºå·®
                    basis_data = self._calculate_basis(symbol, start_date, end_date)
                    loaded_data[req.source.value] = basis_data

                # ... å…¶ä»–æ•¸æ“šæº

            except Exception as e:
                if req.required:
                    raise DataLoadError(f"Failed to load required data {req.source.value}: {e}")
                else:
                    print(f"Warning: Failed to load optional data {req.source.value}: {e}")

        return loaded_data

    def _load_funding_rate_multi_exchange(
        self,
        symbol: str,
        start_date: datetime,
        end_date: datetime,
        exchanges: List[str]
    ) -> pd.DataFrame:
        """è¼‰å…¥å¤šäº¤æ˜“æ‰€è³‡é‡‘è²»ç‡æ•¸æ“š"""

        all_data = []

        for exchange in exchanges:
            try:
                # 1. å˜—è©¦å¾æœ¬åœ°è¼‰å…¥
                local_data = self.storage.load_funding_rate(symbol, exchange, start_date, end_date)

                if local_data.empty or self._need_data_update(local_data, end_date):
                    # 2. å¾APIç²å–æœ€æ–°æ•¸æ“š
                    connector = self.connectors[exchange]
                    api_data = connector.get_funding_rate(symbol, start_date, end_date)

                    # 3. æ•¸æ“šå“è³ªæ§åˆ¶
                    is_valid, errors = self.quality_controller.validate_data(api_data, 'funding_rate')
                    if not is_valid:
                        print(f"Data quality issues for {exchange}: {errors}")
                        api_data = self.quality_controller.clean_data(api_data, 'funding_rate')

                    # 4. ä¿å­˜åˆ°æœ¬åœ°
                    if not api_data.empty:
                        self.storage.save_funding_rate(api_data, symbol, exchange)
                        local_data = api_data

                if not local_data.empty:
                    local_data['exchange'] = exchange
                    all_data.append(local_data)

            except Exception as e:
                print(f"Failed to load funding rate from {exchange}: {e}")
                continue

        if not all_data:
            return pd.DataFrame()

        # 5. å¤šäº¤æ˜“æ‰€æ•¸æ“šèšåˆ
        combined_data = pd.concat(all_data, ignore_index=True)

        # 6. æ•¸æ“šå¾Œè™•ç†ï¼ˆå»é‡ã€æ’åºã€çµ±è¨ˆï¼‰
        return self._aggregate_funding_rate_data(combined_data)

    def _aggregate_funding_rate_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """èšåˆå¤šäº¤æ˜“æ‰€è³‡é‡‘è²»ç‡æ•¸æ“š"""
        if data.empty:
            return data

        # æŒ‰æ™‚é–“æˆ³èšåˆï¼Œè¨ˆç®—çµ±è¨ˆé‡
        aggregated = data.groupby(['timestamp', 'symbol']).agg({
            'funding_rate': ['mean', 'median', 'std', 'count'],
            'predicted_rate': 'mean',
            'mark_price': 'mean'
        }).round(6)

        # æ‰å¹³åŒ–æ¬„ä½åç¨±
        aggregated.columns = [f'funding_{stat}' for stat in ['mean', 'median', 'std', 'count']] + \
                            ['predicted_rate_mean', 'mark_price_mean']

        aggregated = aggregated.reset_index()

        # è¨ˆç®—è¡ç”ŸæŒ‡æ¨™
        aggregated['funding_divergence'] = aggregated['funding_std']  # äº¤æ˜“æ‰€é–“åˆ†æ­§åº¦
        aggregated['funding_confidence'] = aggregated['funding_count'] / len(data['exchange'].unique())

        return aggregated.sort_values('timestamp')
```

---

## ğŸ® äº’å‹•å¼CLIå‡ç´š

### **é¸å–®ç³»çµ±è¨­è¨ˆ**

```python
class InteractiveCLI:
    """äº’å‹•å¼CLIé¸å–®ç³»çµ± v0.5"""

    def __init__(self):
        self.pipeline = get_pipeline()
        self.registry = StrategyRegistry()

    def main_menu(self):
        """ä¸»é¸å–®ç•Œé¢"""
        while True:
            self._clear_screen()
            self._print_header()
            self._print_main_menu()

            choice = input("è«‹é¸æ“‡åŠŸèƒ½ (0-9): ").strip()

            if choice == '1':
                self.strategy_backtest_menu()
            elif choice == '2':
                self.batch_optimization_menu()
            elif choice == '3':
                self.live_simulation_menu()
            elif choice == '4':
                self.data_management_menu()
            elif choice == '5':
                self.strategy_management_menu()
            elif choice == '6':
                self.risk_analysis_menu()
            elif choice == '7':
                self.exchange_connection_menu()
            elif choice == '8':
                self.system_settings_menu()
            elif choice == '9':
                self.help_documentation_menu()
            elif choice == '0':
                print("æ„Ÿè¬ä½¿ç”¨ SuperDogï¼å†è¦‹ï¼")
                break
            else:
                print("ç„¡æ•ˆé¸æ“‡ï¼Œè«‹é‡æ–°è¼¸å…¥...")
                time.sleep(1)

    def _print_header(self):
        """æ‰“å°æ¨™é¡Œ"""
        print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print("â•‘                    SuperDog Backtest v0.5                    â•‘")
        print("â•‘                 æ°¸çºŒåˆç´„é‡åŒ–äº¤æ˜“åˆ†æå¹³å°                         â•‘")
        print("â•‘                                                               â•‘")
        print(f"â•‘  SSD ç‹€æ…‹: {'âœ… å·²é€£æ¥' if self._check_ssd_status() else 'âŒ æœªé€£æ¥'}   ")
        print(f"â•‘  ç­–ç•¥æ•¸é‡: {len(self.registry.list_strategies())} å€‹")
        print(f"â•‘  æ•¸æ“šæº: {self._get_available_data_sources()}")
        print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")

    def _print_main_menu(self):
        """æ‰“å°ä¸»é¸å–®"""
        print("â•‘  1. ğŸ“Š ç­–ç•¥å›æ¸¬                                               â•‘")
        print("â•‘  2. âš™ï¸  æ‰¹é‡åƒæ•¸å„ªåŒ–                                          â•‘")
        print("â•‘  3. ğŸ”´ å¯¦ç›¤æ¨¡æ“¬äº¤æ˜“                                           â•‘")
        print("â•‘  4. ğŸ“ æ•¸æ“šç®¡ç†                                               â•‘")
        print("â•‘  5. ğŸ§  ç­–ç•¥ç®¡ç†                                               â•‘")
        print("â•‘  6. âš ï¸  é¢¨éšªåˆ†æ                                              â•‘")
        print("â•‘  7. ğŸŒ äº¤æ˜“æ‰€é€£ç·š                                             â•‘")
        print("â•‘  8. âš™ï¸  ç³»çµ±è¨­ç½®                                              â•‘")
        print("â•‘  9. â“ å¹«åŠ©æ–‡æª”                                               â•‘")
        print("â•‘  0. ğŸšª é€€å‡º                                                   â•‘")
        print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

    def strategy_backtest_menu(self):
        """ç­–ç•¥å›æ¸¬å­é¸å–®"""
        self._clear_screen()
        self._print_submenu_header("ç­–ç•¥å›æ¸¬")

        # 1. é¸æ“‡ç­–ç•¥
        strategies = self.registry.list_strategies()
        print("å¯ç”¨ç­–ç•¥:")
        for i, strategy in enumerate(strategies, 1):
            print(f"  {i}. {strategy}")

        strategy_choice = self._get_choice_input("é¸æ“‡ç­–ç•¥", 1, len(strategies))
        selected_strategy = strategies[strategy_choice - 1]

        # 2. é¸æ“‡äº¤æ˜“å°
        symbols = get_top_symbols(10)
        print("\nå¯ç”¨äº¤æ˜“å°:")
        for i, symbol in enumerate(symbols, 1):
            print(f"  {i}. {symbol}")

        symbol_choice = self._get_choice_input("é¸æ“‡äº¤æ˜“å°", 1, len(symbols))
        selected_symbol = symbols[symbol_choice - 1]

        # 3. é¸æ“‡æ™‚é–“é€±æœŸ
        timeframes = ['1m', '5m', '15m', '30m', '1h', '4h', '1d']
        print("\nå¯ç”¨æ™‚é–“é€±æœŸ:")
        for i, tf in enumerate(timeframes, 1):
            print(f"  {i}. {tf}")

        tf_choice = self._get_choice_input("é¸æ“‡æ™‚é–“é€±æœŸ", 1, len(timeframes))
        selected_timeframe = timeframes[tf_choice - 1]

        # 4. å‹•æ…‹è¨­ç½®ç­–ç•¥åƒæ•¸
        strategy_instance = self.registry.get_strategy(selected_strategy)()
        parameters = strategy_instance.get_parameters()

        print("\nç­–ç•¥åƒæ•¸è¨­ç½®:")
        param_values = {}
        for param_name, param_spec in parameters.items():
            current_value = input(
                f"  {param_spec.description} (é è¨­: {param_spec.default_value}): "
            ).strip()

            if current_value:
                param_values[param_name] = param_spec.validate(current_value)
            else:
                param_values[param_name] = param_spec.default_value

        # 5. åŸ·è¡Œå›æ¸¬
        print(f"\nåŸ·è¡Œå›æ¸¬: {selected_strategy} on {selected_symbol} {selected_timeframe}")
        print("åƒæ•¸:", param_values)

        if input("ç¢ºèªåŸ·è¡Œ? (y/N): ").lower() == 'y':
            self._run_backtest(selected_strategy, selected_symbol, selected_timeframe, param_values)

        input("\næŒ‰ä»»æ„éµè¿”å›ä¸»é¸å–®...")

    def data_management_menu(self):
        """æ•¸æ“šç®¡ç†å­é¸å–®"""
        self._clear_screen()
        self._print_submenu_header("æ•¸æ“šç®¡ç†")

        print("1. ğŸ“¥ ä¸‹è¼‰æ­·å²æ•¸æ“š")
        print("2. ğŸ”„ æ›´æ–°æ•¸æ“š")
        print("3. ğŸ§¹ æ¸…ç†æ•¸æ“š")
        print("4. ğŸ“Š æ•¸æ“šçµ±è¨ˆ")
        print("5. âœ… æ•¸æ“šå“è³ªæª¢æŸ¥")
        print("0. ğŸ”™ è¿”å›ä¸»é¸å–®")

        choice = input("\nè«‹é¸æ“‡æ“ä½œ: ").strip()

        if choice == '1':
            self._download_historical_data_wizard()
        elif choice == '2':
            self._update_data_wizard()
        elif choice == '3':
            self._clean_data_wizard()
        elif choice == '4':
            self._show_data_statistics()
        elif choice == '5':
            self._run_data_quality_check()

    def _download_historical_data_wizard(self):
        """æ­·å²æ•¸æ“šä¸‹è¼‰åš®å°"""
        print("\nğŸ“¥ æ­·å²æ•¸æ“šä¸‹è¼‰åš®å°")
        print("=" * 50)

        # é¸æ“‡æ•¸æ“šé¡å‹
        data_types = ['OHLCV', 'Funding Rate', 'Open Interest', 'Liquidations']
        print("æ•¸æ“šé¡å‹:")
        for i, dt in enumerate(data_types, 1):
            print(f"  {i}. {dt}")

        type_choice = self._get_choice_input("é¸æ“‡æ•¸æ“šé¡å‹", 1, len(data_types))
        selected_type = data_types[type_choice - 1]

        # é¸æ“‡äº¤æ˜“æ‰€
        exchanges = ['Binance', 'Bybit', 'OKX']
        print("\näº¤æ˜“æ‰€:")
        for i, ex in enumerate(exchanges, 1):
            print(f"  {i}. {ex}")

        exchange_choice = self._get_choice_input("é¸æ“‡äº¤æ˜“æ‰€", 1, len(exchanges))
        selected_exchange = exchanges[exchange_choice - 1].lower()

        # é¸æ“‡äº¤æ˜“å°
        symbol = input("äº¤æ˜“å° (å¦‚BTCUSDT): ").strip().upper()

        # é¸æ“‡æ™‚é–“ç¯„åœ
        days = int(input("ä¸‹è¼‰å¤©æ•¸ (é è¨­30): ") or "30")

        # åŸ·è¡Œä¸‹è¼‰
        print(f"\né–‹å§‹ä¸‹è¼‰ {selected_type} æ•¸æ“š...")
        print(f"äº¤æ˜“æ‰€: {selected_exchange}")
        print(f"äº¤æ˜“å°: {symbol}")
        print(f"å¤©æ•¸: {days}")

        if input("ç¢ºèªä¸‹è¼‰? (y/N): ").lower() == 'y':
            try:
                self._execute_data_download(selected_type, selected_exchange, symbol, days)
                print("âœ… æ•¸æ“šä¸‹è¼‰å®Œæˆ!")
            except Exception as e:
                print(f"âŒ ä¸‹è¼‰å¤±æ•—: {e}")

        input("\næŒ‰ä»»æ„éµç¹¼çºŒ...")
```

---

## ğŸ“‹ å¯¦ä½œéšæ®µè¦åŠƒ

### **Phase A: æ ¸å¿ƒæ•¸æ“šæºå¯¦ä½œ** (2é€±)

#### **Week 1: è³‡é‡‘è²»ç‡ + æŒå€‰é‡**
```python
# å¯¦ä½œæ¸…å–®
1. data/exchanges/binance_connector.py     # Binance APIé€£æ¥å™¨
2. data/exchanges/bybit_connector.py       # Bybit APIé€£æ¥å™¨
3. data/exchanges/okx_connector.py         # OKX APIé€£æ¥å™¨
4. data/perpetual/funding_rate.py          # è³‡é‡‘è²»ç‡æ•¸æ“šè™•ç†
5. data/perpetual/open_interest.py         # æŒå€‰é‡æ•¸æ“šè™•ç†
6. data/perpetual/storage.py               # æ°¸çºŒæ•¸æ“šå­˜å„²
7. data/quality/controller.py              # æ•¸æ“šå“è³ªæ§åˆ¶
8. tests/test_perpetual_data.py            # æ°¸çºŒæ•¸æ“šæ¸¬è©¦
```

#### **Week 2: åŸºå·® + çˆ†å€‰ + å¤šç©ºæ¯”**
```python
# å¯¦ä½œæ¸…å–®
9. data/perpetual/basis.py                 # æœŸç¾åŸºå·®è¨ˆç®—
10. data/perpetual/liquidations.py         # çˆ†å€‰æ•¸æ“šè™•ç†
11. data/perpetual/long_short_ratio.py     # å¤šç©ºæ¯”æ•¸æ“š
12. data/aggregation/multi_exchange.py     # å¤šäº¤æ˜“æ‰€èšåˆ
13. æ›´æ–° data/pipeline.py                  # æ•´åˆåˆ°æ•¸æ“šç®¡é“
14. tests/test_data_aggregation.py         # èšåˆåŠŸèƒ½æ¸¬è©¦
```

### **Phase B: CLIå‡ç´š** (1é€±)

#### **Week 3: äº’å‹•å¼ç•Œé¢**
```python
# å¯¦ä½œæ¸…å–®
15. cli/interactive/main_menu.py           # ä¸»é¸å–®ç³»çµ±
16. cli/interactive/strategy_menu.py       # ç­–ç•¥å›æ¸¬é¸å–®
17. cli/interactive/data_menu.py           # æ•¸æ“šç®¡ç†é¸å–®
18. cli/interactive/utils.py               # CLIå·¥å…·å‡½æ•¸
19. cli/wizards/data_download.py           # æ•¸æ“šä¸‹è¼‰åš®å°
20. cli/wizards/backtest_config.py         # å›æ¸¬é…ç½®åš®å°
21. æ›´æ–° cli/main.py                       # æ•´åˆäº’å‹•æ¨¡å¼
22. tests/test_interactive_cli.py          # CLIæ¸¬è©¦
```

### **Phase C: æ•´åˆèˆ‡å„ªåŒ–** (0.5é€±)

#### **Week 3.5: æœ€çµ‚æ•´åˆ**
```python
# æ•´åˆæ¸…å–®
23. ç«¯åˆ°ç«¯æ¸¬è©¦ - å®Œæ•´æ•¸æ“šæµæ¸¬è©¦
24. æ€§èƒ½å„ªåŒ– - æ•¸æ“šè¼‰å…¥æ•ˆèƒ½æå‡
25. æ–‡æª”æ›´æ–° - README, CHANGELOG, APIæ–‡æª”
26. ç¤ºç¯„ç­–ç•¥ - åŸºæ–¼æ–°æ•¸æ“šæºçš„ç­–ç•¥ç¯„ä¾‹
```

---

## âœ… æˆåŠŸæŒ‡æ¨™

### **åŠŸèƒ½æŒ‡æ¨™**
- [ ] **7ç¨®æ°¸çºŒæ•¸æ“šæº** - å…¨éƒ¨å¯æ­£å¸¸è¼‰å…¥ä½¿ç”¨
- [ ] **3å€‹äº¤æ˜“æ‰€æ”¯æ´** - Binance/Bybit/OKXæ•¸æ“šèšåˆ
- [ ] **æ•¸æ“šå“è³ªæ§åˆ¶** - 90%+æ•¸æ“šé€šéå“è³ªæª¢æŸ¥
- [ ] **äº’å‹•å¼CLI** - é¸å–®å¼æ“ä½œå…¨éƒ¨åŠŸèƒ½
- [ ] **å‘å¾Œå…¼å®¹** - v0.4æ‰€æœ‰åŠŸèƒ½æ­£å¸¸é‹ä½œ

### **æŠ€è¡“æŒ‡æ¨™**
- [ ] **APIéŸ¿æ‡‰æ™‚é–“** - å–®æ¬¡æ•¸æ“šè«‹æ±‚<5ç§’
- [ ] **å­˜å„²æ•ˆç‡** - parquetæ ¼å¼å£“ç¸®æ¯”>80%
- [ ] **æ•¸æ“šè¦†è“‹** - æ¯å€‹äº¤æ˜“å°>90å¤©æ­·å²æ•¸æ“š
- [ ] **æ¸¬è©¦è¦†è“‹ç‡** - æ–°ä»£ç¢¼85%+æ¸¬è©¦è¦†è“‹

### **é«”é©—æŒ‡æ¨™**
- [ ] **ç­–ç•¥é–‹ç™¼** - 10åˆ†é˜å…§å®Œæˆå·æ²ç­–ç•¥ç·¨å¯«
- [ ] **æ•¸æ“šç²å–** - 3æ­¥é©Ÿå®Œæˆæ­·å²æ•¸æ“šä¸‹è¼‰
- [ ] **å›æ¸¬åŸ·è¡Œ** - CLIé¸å–®å¼åŸ·è¡Œç­–ç•¥å›æ¸¬
- [ ] **éŒ¯èª¤è™•ç†** - å‹å¥½éŒ¯èª¤è¨Šæ¯å’Œä¿®å¾©å»ºè­°

---

## ğŸ¯ å·æ²ç­–ç•¥ç¤ºç¯„

åŸºæ–¼æ–°çš„æ°¸çºŒæ•¸æ“šæºï¼Œå·æ²ç­–ç•¥å°‡èƒ½å¯¦ç¾å®Œæ•´åŠŸèƒ½ï¼š

```python
class KawamokuAdvancedStrategy(BaseStrategy):
    """å·æ²é€²éšå¤šå› å­ç­–ç•¥ - åŸºæ–¼æ°¸çºŒåˆç´„æ•¸æ“š"""

    def get_parameters(self):
        return {
            'funding_threshold': float_param(0.01, "è³‡é‡‘è²»ç‡é–¾å€¼", 0.001, 0.05),
            'oi_momentum_period': int_param(24, "æŒå€‰é‡å‹•é‡é€±æœŸ", 6, 72),
            'basis_mean_revert': bool_param(True, "åŸºå·®å‡å€¼å›æ­¸"),
            'liquidation_weight': float_param(0.3, "çˆ†å€‰æŒ‡æ¨™æ¬Šé‡", 0.0, 1.0),
            'multi_exchange': bool_param(True, "å¤šäº¤æ˜“æ‰€æ•¸æ“šèšåˆ")
        }

    def get_data_requirements(self):
        return [
            DataRequirement(DataSource.OHLCV, lookback_periods=200),
            DataRequirement(DataSource.FUNDING_RATE, lookback_periods=100),
            DataRequirement(DataSource.OPEN_INTEREST, lookback_periods=200),
            DataRequirement(DataSource.BASIS, lookback_periods=100),
            DataRequirement(DataSource.LIQUIDATIONS, lookback_periods=30),
            DataRequirement(DataSource.LONG_SHORT_RATIO, lookback_periods=100)
        ]

    def compute_signals(self, data: Dict[str, pd.DataFrame], params: Dict) -> pd.Series:
        """å·æ²å¤šå› å­ä¿¡è™Ÿè¨ˆç®—"""

        # 1. è³‡é‡‘è²»ç‡ä¿¡è™Ÿ
        funding = data['funding_rate']
        funding_signal = self._funding_rate_signal(funding, params['funding_threshold'])

        # 2. æŒå€‰é‡å‹•é‡ä¿¡è™Ÿ
        oi = data['open_interest']
        oi_signal = self._oi_momentum_signal(oi, params['oi_momentum_period'])

        # 3. åŸºå·®å›æ­¸ä¿¡è™Ÿ
        basis = data['basis']
        basis_signal = self._basis_reversion_signal(basis) if params['basis_mean_revert'] else 0

        # 4. çˆ†å€‰ææ…Œä¿¡è™Ÿ
        liquidations = data['liquidations']
        liq_signal = self._liquidation_panic_signal(liquidations, params['liquidation_weight'])

        # 5. å¤šç©ºæ¯”é€†å‘ä¿¡è™Ÿ
        long_short = data['long_short_ratio']
        contrarian_signal = self._contrarian_signal(long_short)

        # 6. å¤šå› å­åŠ æ¬Šåˆæˆ
        combined_signal = (
            funding_signal * 0.25 +
            oi_signal * 0.25 +
            basis_signal * 0.20 +
            liq_signal * params['liquidation_weight'] +
            contrarian_signal * 0.15
        )

        # 7. ä¿¡è™Ÿå¹³æ»‘å’Œé–¾å€¼è™•ç†
        smoothed_signal = combined_signal.rolling(3).mean()

        signals = pd.Series(0, index=combined_signal.index)
        signals[smoothed_signal > 0.6] = 1   # å¼·å¤šé ­ä¿¡è™Ÿ
        signals[smoothed_signal < -0.6] = -1 # å¼·ç©ºé ­ä¿¡è™Ÿ

        return signals

    def _funding_rate_signal(self, funding: pd.DataFrame, threshold: float) -> pd.Series:
        """è³‡é‡‘è²»ç‡ä¿¡è™Ÿï¼šæ¥µç«¯è²»ç‡çš„åè½‰ä¿¡è™Ÿ"""
        rate_mean = funding['funding_mean'] if 'funding_mean' in funding else funding['funding_rate']

        # æ¥µç«¯æ­£è²»ç‡ -> ç©ºé ­ä¿¡è™Ÿ (å¤šé ­éåº¦æ“æ“ )
        # æ¥µç«¯è² è²»ç‡ -> å¤šé ­ä¿¡è™Ÿ (ç©ºé ­éåº¦æ“æ“ )
        signal = pd.Series(0, index=rate_mean.index)
        signal[rate_mean > threshold] = -1
        signal[rate_mean < -threshold] = 1

        return signal

    def _oi_momentum_signal(self, oi: pd.DataFrame, period: int) -> pd.Series:
        """æŒå€‰é‡å‹•é‡ä¿¡è™Ÿï¼šOIè®ŠåŒ–è¶¨å‹¢"""
        oi_change = oi['open_interest'].pct_change(period)

        signal = pd.Series(0, index=oi_change.index)
        signal[oi_change > 0.2] = 1   # OIå¤§å¹…å¢åŠ  -> è¶¨å‹¢ä¿¡è™Ÿ
        signal[oi_change < -0.2] = -1 # OIå¤§å¹…æ¸›å°‘ -> åè½‰ä¿¡è™Ÿ

        return signal
```

**é€™æ¨£å·æ²ç­–ç•¥å°±èƒ½å……åˆ†åˆ©ç”¨æ‰€æœ‰æ°¸çºŒåˆç´„æ•¸æ“šï¼Œå¯¦ç¾çœŸæ­£çš„å¤šå› å­é‡åŒ–äº¤æ˜“ï¼** ğŸš€

---

*æœ€å¾Œæ›´æ–°: 2025-12-07*
*è¦æ ¼ç‰ˆæœ¬: v1.0*
*é è¨ˆé–‹ç™¼æ™‚ç¨‹: 3-4é€±*
